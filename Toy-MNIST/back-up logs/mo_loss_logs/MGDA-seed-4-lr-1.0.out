Namespace(batch_size=64, beta_moco=0.1, gamma_moco=0.1, gamma_modo=0.1, lr=1.0, moo_method='MGDA', num_epochs=1000, rho_moco=0.1, rho_modo=0.1, seed=4)

==================================================
Model parameter count per layer
==================================================
fc1.weight 	: 401408
fc1.bias 	: 512
fc2.weight 	: 5120
fc2.bias 	: 10
Total number of parametrs : 407050
--------------------------------------------------

================================================================================
LOG FORMAT: Epoch: EPOCH | Train: LOSS1 LOSS2 LOSS3 | Test: LOSS1 LOSS2 LOSS3
================================================================================
Epoch:      0 | Train: 2.3068 0.1796 0.8833 | Test: 2.3125 0.1797 0.889
Epoch:    100 | Train: 1.2963 0.0639 0.379 | Test: 1.3097 0.0633 0.3832
Epoch:    200 | Train: 0.8339 0.0454 0.2054 | Test: 0.8301 0.0444 0.2023
Epoch:    300 | Train: 0.442 0.0308 0.0981 | Test: 0.4076 0.0291 0.089
Epoch:    400 | Train: 0.4246 0.026 0.0962 | Test: 0.3998 0.0247 0.0893
Epoch:    500 | Train: 0.4591 0.0247 0.1043 | Test: 0.4394 0.0239 0.0985
Epoch:    600 | Train: 0.4545 0.0225 0.1057 | Test: 0.433 0.0219 0.0993
Epoch:    700 | Train: 0.4579 0.0216 0.1065 | Test: 0.4335 0.0208 0.1002
Epoch:    800 | Train: 0.4609 0.0211 0.1061 | Test: 0.4353 0.0201 0.1003
Epoch:    900 | Train: 0.4844 0.0207 0.1142 | Test: 0.4541 0.02 0.1073
Epoch:    999 | Train: 0.497 0.021 0.116 | Test: 0.479 0.0205 0.1117

================================================================================
PERF FORMAT: DATASET | Acuracy: ACC | Loss: LOSS1 LOSS2 LOSS3 | PS: PS
======================================================================
Train | Acuracy:  90.95% | Loss: 0.49344 0.02076 0.11533 | PS: 0.02509 
Val   | Acuracy:  90.07% | Loss: 0.51607 0.0221 0.11574 | PS: 0.019 
Test  | Acuracy:  91.06% | Loss: 0.47686 0.02038 0.11102 | PS: 0.02576 
--------------------------------------------------------------------------------
Optimization error  : 0.02509
Population error    : 0.02576
Generalization error: 0.00067
